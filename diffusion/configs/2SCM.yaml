unets:
  unet1: # BASE
    dim: 64
    num_resnet_blocks: 2
    dim_mults: [1,2,4]
    max_text_len: 1
    layer_attns: False
    layer_cross_attns: [False, False, True]
    cond_images_channels: 3
  unet2: # TSSR
    dim: 64
    num_resnet_blocks: 2
    dim_mults: [1,2,4]
    max_text_len: 1
    layer_attns: False
    layer_cross_attns: [False, False, True]
    memory_efficient: True
    cond_images_channels: 3

imagen:
  elucidated: True
  condition_on_text: True
  image_sizes: [56, 112] # BASE UNnet generates 56x56, and TSSR generates 112x112
  text_embed_dim: 1
  num_sample_steps: [32, 64]
  random_crop_sizes: [null, 56]
  temporal_downsample_factor: [4, 1] # BASE UNnet generates at 8fps, and TSSR generates at 32fps
  sigma_min: 0.002
  sigma_max: 80
  sigma_data: 0.25
  rho: 7
  P_mean: -1.2
  P_std: 1.2
  S_churn: [80, 160] # Determined empirically as working values
  S_tmin: 0.05
  S_tmax: 50
  S_noise: 1.003
  resize_mode: 'trilinear'


trainer:
  split_batches: False
  lr: 5e-4
  dl_tuple_output_keywords_names: ['images', 'text_embeds', 'cond_images']

dataset:
  data_path: "./data/EchoNet-Dynamic"
  deactivate_cache: False
  fps: 32 # frames per second of final video in the cascade
  duration: 2.0 # seconds
  grayscale: False

dataloader: # This is adapted when launching the training script
  batch_size: 8
  num_workers: 8

wandb:
  project: ""
  entity: ""

checkpoint:
  path: "./outputs/diffusion"
  batch_size: 4
  cond_scale: 5.
  save_every_x_it: 5000

